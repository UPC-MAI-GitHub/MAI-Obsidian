![[T12_2023_students.pdf]]

## Notes

- **LEARNING OBJECTIVES*
	- Understand key concepts of _bias_ and _fairness_
	- *Raise awareness* on the importance and relevance of considering *data and algorithmic bias and fairness* issues in Machine Learning
	- Showcase approaches that *mitigate bias/fairness* along with the recommendation pipeline and assess their influence on stakeholders
	- Play with recommendation pipelines and conduct exploratory analysis aimed at uncovering sources of bias along them
- **WHAT IS AI AND MACHINE LEARNING?**
    - *AI* is a term describing *techniques to make computers behave intelligently*.
    - *Machine learning* is a *major topic in AI*, involving *algorithms that learn* to make decisions or structure data.
        - Includes _supervised_ and _unsupervised learning_, and _reinforcement learning_.
- **DEFINITIONS**
    - **Bias:** "*inclination* or *prejudice* for or *against one person or group* especially in a way considered to be *unfair*."
    - **Fairness:** "*impartial and just treatment* or behavior without favoritism or discrimination."
        - In Machine Learning context: *An algorithm is fair if it does not favor or discriminate against certain individuals or groups* based on sensitive characteristics.
- **EXAMPLES OF BIAS**
    - In computer vision, facial analysis models, word embeddings, and historical data.
    - Notable case studies include bias in healthcare algorithms and job candidate screening.
- **TYPES OF BIAS**
    - *Data to Algorithm*: Measurement, Omitted Variable, Representation, Aggregation, Sampling, Longitudinal Data, Linking Bias.
    - *Algorithm to User*: Algorithm, User Interaction, Presentation, Ranking, Popularity, Emergent, Evaluation Bias.
    - *User to Data*: Historical, Population, Self-selection, Social, Behavioral, Temporal, Content Production Bias.
    - ![[Pasted image 20240108234309.png|400]]
- **DISCRIMINATION**
    - Discrimination as a source for unfairness due to human prejudice and stereotyping.
    - Types: Systemic, Statistical, Explainable, and Unexplainable Discrimination.
- *Equality and Equity are not Synonyms!!*
	- ![[Pasted image 20240108234536.png]]
- **WHEN MIGHT AI BE UNFAIR OR DISCRIMINATORY?**
    - Factors include *inaccurate or insufficient data*, *variables influencing outcomes differently by group*, and the availability of less discriminatory models.
- **WHAT DOES IT MEANS FOR AI TO BE FAIR?**
    - Fairness in AI involves concepts like *Anti-classification*, *Classification parity*, *Calibration*, and various mathematical definitions.
- **METHODS FOR FAIR MACHINE LEARNING**
    - Addressing fairness through *Pre-processing*, I*n-processing*, and *Post-processing*.
    - ![[Pasted image 20240108235623.png|550]]
- **BIAS AND FAIRNESS IN RECOMMENDER SYSTEMS**
    - Focus on the recommendation pipeline, core stakeholders, and the impact of bias on different perspectives and ethical aspects.
    - *Bias in data recomendation*
	    - *Selection bias* happens as users are free to choose which items to rate, so that the observed ratings are not a representative sample of all ratings. 
	    - *Conformity bias* happens as users tend to rate similarly to the others in a group, even if doing so goes against their own judgment.
	    - *Exposure bias* happens as users are only exposed to a part of specific items so that unobserved interactions do not always represent negative preference 
	    - *Position bias* happens as users tend to interact with items in higher position of the recommendation list regardless
	- *Bias in model recommendation*
	    - *Inductive bias* denotes the assumptions made by the model to better learn the target function and to generalize beyond training data 
	    - *Popularity bias* Popular items are recommended even more frequently than their popularity would warrant 
	    - *Unfairness* The system systematically 
	- *Bias Associated to users*
		- *Population biases*, differences in demographics or other user characteristics, between a population of users represented in a dataset/platform and a target population
		- *Behavioural biases*, differences in user behaviour across platforms or contexts, or across users represented in different datasets 
		- *Content biases*, behavioural biases that are expressed as lexical, syntactic, semantic, and structural differences in the contents generated by users 
		- *Linking biases*, behavioural biases that are expressed as differences in the attributes of networks obtained from user connections, interactions or activity 
		- *Temporal biases*, differences in populations or behaviours over time
- **HANDS ON BIAS IN RECSYS**
    - Practical exercises and tutorials on addressing bias in Recommender Systems.
    - ![[Pasted image 20240109002408.png]]